{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3DR-eO17geWu"
   },
   "source": [
    "# Handwriting Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EMefrVPCg-60"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (2.10.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorflow) (1.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorflow) (22.9.24)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\karunakar reddy\\anaconda3\\lib\\site-packages (2.10.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator Generate batches of tensor image data with real-time data augmentation.\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oxQxCBWyoGPE"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MvE-heJNo3GG"
   },
   "source": [
    "### Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37340 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# horizontal flip augmentation means they will reverse the column-wise.\n",
    "training_datagen= ImageDataGenerator(rescale= 1./225,\n",
    "                                    shear_range= 0.2,\n",
    "                                    zoom_range= 0.2,\n",
    "                                    horizontal_flip= True)\n",
    "# target size, the dimensions to which all images found will be resized\n",
    "training_set= training_datagen.flow_from_directory('datasets/Handwriting Recognition/training_set',\n",
    "                                                  target_size= (28, 28),\n",
    "                                                  class_mode= 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mrCMmGw9pHys"
   },
   "source": [
    "### Preprocessing the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4660 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen= ImageDataGenerator(rescale= 1./225,\n",
    "                                shear_range= 0.2,\n",
    "                                zoom_range= 0.2,\n",
    "                                horizontal_flip= True)\n",
    "test_data= test_datagen.flow_from_directory('datasets/Handwriting Recognition/test_set',\n",
    "                                           target_size= (28, 28),\n",
    "                                           batch_size= 32,\n",
    "                                           class_mode= 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "af8O4l90gk7B"
   },
   "source": [
    "## Part 2 - Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ces1gXY2lmoX"
   },
   "source": [
    "### Initialising the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential() provides training and inference features on this model.\n",
    "cnn= tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u5YJj_XMl5LF"
   },
   "source": [
    "### Step 1 - Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters: the number of output filters in the convolution\n",
    "# specifying the depth, height and width of the 3D convolution\n",
    "# activation: Applies the rectified linear unit activation function.\n",
    "cnn.add(tf.keras.layers.Conv2D(filters= 32,kernel_size= 3, activation= 'relu', input_shape= [28, 28, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tf87FpvxmNOJ"
   },
   "source": [
    "### Step 2 - Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strides used to specifies how far the pooling window moves for each pooling step.\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size= 2, strides= 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xaTOgD8rm4mU"
   },
   "source": [
    "### Adding a second convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters= 32, kernel_size= 2, activation= 'relu', input_shape= [28, 28, 3]))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size= 2, strides= 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tmiEuvTunKfk"
   },
   "source": [
    "### Step 3 - Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dAoSECOm203v"
   },
   "source": [
    "### Step 4 - Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense is dimensionality of the output space.\n",
    "cnn.add(tf.keras.layers.Dense(units= 64, activation= 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yTldFvbX28Na"
   },
   "source": [
    "### Step 5 - Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units= 10, activation= 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D6XkI90snSDl"
   },
   "source": [
    "## Part 3 - Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vfrFQACEnc6i"
   },
   "source": [
    "### Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam is an algorithm for optimization technique for gradient descent.\n",
    "# CategoricalCrossentropy: Computes the crossentropy loss between the labels and predictions.\n",
    "# Accuracy which is simple comparison between how many target values matches the predicted values\n",
    "cnn.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ehS-v3MIpX2h"
   },
   "source": [
    "### Training the CNN on the Training set and evaluating it on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1167/1167 [==============================] - 43s 36ms/step - loss: 0.3881 - accuracy: 0.8720 - val_loss: 0.1771 - val_accuracy: 0.9440\n",
      "Epoch 2/20\n",
      "1167/1167 [==============================] - 31s 27ms/step - loss: 0.1406 - accuracy: 0.9552 - val_loss: 0.1041 - val_accuracy: 0.9685\n",
      "Epoch 3/20\n",
      "1167/1167 [==============================] - 32s 27ms/step - loss: 0.1058 - accuracy: 0.9664 - val_loss: 0.0957 - val_accuracy: 0.9691\n",
      "Epoch 4/20\n",
      "1167/1167 [==============================] - 32s 27ms/step - loss: 0.0870 - accuracy: 0.9729 - val_loss: 0.0818 - val_accuracy: 0.9730\n",
      "Epoch 5/20\n",
      "1167/1167 [==============================] - 32s 27ms/step - loss: 0.0750 - accuracy: 0.9765 - val_loss: 0.0778 - val_accuracy: 0.9775\n",
      "Epoch 6/20\n",
      "1167/1167 [==============================] - 31s 27ms/step - loss: 0.0673 - accuracy: 0.9787 - val_loss: 0.0625 - val_accuracy: 0.9794\n",
      "Epoch 7/20\n",
      "1167/1167 [==============================] - 31s 27ms/step - loss: 0.0620 - accuracy: 0.9801 - val_loss: 0.0714 - val_accuracy: 0.9792\n",
      "Epoch 8/20\n",
      "1167/1167 [==============================] - 32s 27ms/step - loss: 0.0552 - accuracy: 0.9826 - val_loss: 0.0646 - val_accuracy: 0.9777\n",
      "Epoch 9/20\n",
      "1167/1167 [==============================] - 32s 28ms/step - loss: 0.0504 - accuracy: 0.9842 - val_loss: 0.0640 - val_accuracy: 0.9788\n",
      "Epoch 10/20\n",
      "1167/1167 [==============================] - 31s 27ms/step - loss: 0.0463 - accuracy: 0.9852 - val_loss: 0.0690 - val_accuracy: 0.9792\n",
      "Epoch 11/20\n",
      "1167/1167 [==============================] - 32s 27ms/step - loss: 0.0439 - accuracy: 0.9859 - val_loss: 0.0608 - val_accuracy: 0.9779\n",
      "Epoch 12/20\n",
      "1167/1167 [==============================] - 32s 27ms/step - loss: 0.0425 - accuracy: 0.9866 - val_loss: 0.0689 - val_accuracy: 0.9803\n",
      "Epoch 13/20\n",
      "1167/1167 [==============================] - 31s 27ms/step - loss: 0.0401 - accuracy: 0.9870 - val_loss: 0.0512 - val_accuracy: 0.9839\n",
      "Epoch 14/20\n",
      "1167/1167 [==============================] - 31s 27ms/step - loss: 0.0377 - accuracy: 0.9884 - val_loss: 0.0539 - val_accuracy: 0.9837\n",
      "Epoch 15/20\n",
      "1167/1167 [==============================] - 32s 28ms/step - loss: 0.0348 - accuracy: 0.9884 - val_loss: 0.0502 - val_accuracy: 0.9835\n",
      "Epoch 16/20\n",
      "1167/1167 [==============================] - 32s 27ms/step - loss: 0.0343 - accuracy: 0.9890 - val_loss: 0.0506 - val_accuracy: 0.9858\n",
      "Epoch 17/20\n",
      "1167/1167 [==============================] - 31s 27ms/step - loss: 0.0314 - accuracy: 0.9894 - val_loss: 0.0550 - val_accuracy: 0.9826\n",
      "Epoch 18/20\n",
      "1167/1167 [==============================] - 31s 27ms/step - loss: 0.0315 - accuracy: 0.9899 - val_loss: 0.0551 - val_accuracy: 0.9818\n",
      "Epoch 19/20\n",
      "1167/1167 [==============================] - 35s 30ms/step - loss: 0.0310 - accuracy: 0.9901 - val_loss: 0.0529 - val_accuracy: 0.9854\n",
      "Epoch 20/20\n",
      "1167/1167 [==============================] - 34s 29ms/step - loss: 0.0273 - accuracy: 0.9914 - val_loss: 0.0519 - val_accuracy: 0.9830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x181da852580>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs means training the neural network with all the training data for one cycle.\n",
    "cnn.fit(x= training_set, validation_data= test_data, epochs= 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U3PZasO0006Z"
   },
   "source": [
    "## Part 4 - Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image= tf.keras.preprocessing.image.load_img('datasets/Handwriting Recognition/single_prediction/img_50.jpg', target_size= (28, 28))\n",
    "test_image= tf.keras.preprocessing.image.img_to_array(test_image)\n",
    "test_image= np.expand_dims(test_image, axis= 0)\n",
    "result= cnn.predict(test_image)\n",
    "if result[0][0] == 1:\n",
    "    prediction= 'Zero'\n",
    "elif result[0][1] == 1:\n",
    "    prediction= 'One'\n",
    "elif result[0][2] == 1:\n",
    "    prediction= 'Two'\n",
    "elif result[0][3] == 1:\n",
    "    prediction= 'Three'\n",
    "elif result[0][4] == 1:\n",
    "    prediction= 'Four'\n",
    "elif result[0][5] == 1:\n",
    "    prediction= 'Five'\n",
    "elif result[0][6] == 1:\n",
    "    prediction= 'Six'\n",
    "elif result[0][7] == 1:\n",
    "    prediction= 'Seven'\n",
    "elif result[0][8] == 1:\n",
    "    prediction= 'Eight'\n",
    "else:\n",
    "    prediction= 'Nine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seven\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "convolutional_neural_network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
